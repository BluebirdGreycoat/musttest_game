
-- Why did I decide to write this? I played a fort-raid with family and realized
-- how crummy the fortress gen was.

local HASH_POSITION = minetest.hash_node_position
local UNHASH_POSITION = minetest.get_position_from_hash
local POS_TO_STR = minetest.pos_to_string



-- Returns the INTERSECTION of elements in two input lists.
-- Both lists should be indexed by chunkname key. Value is ignored.
local function intersect(a, b)
	local set = {}
	for key, _ in pairs(b) do set[key] = true end
	local res = {}
	for key, _ in pairs(a) do if set[key] then res[key] = true end end
	return res
end



-- This function checks if a location was already generated by a PREVIOUS run
-- of this fortress generator algorithm, and written to map.
-- We have to take into account relative positions, which involves some
-- unhashing/rehashing.
local function already_claimed(spawnpos, step, hashpos, previous)
	local vec_add = vector.add
	local vec_mult = vector.multiply
	local chunkpos = UNHASH_POSITION(hashpos)
	local realpos = vec_add(spawnpos, vec_mult(chunkpos, step))
	local finalhash = HASH_POSITION(realpos)
	return previous[finalhash]
end



-- Selects the next chunk LOCATION from the list of potential locations where a
-- chunk could be spawned. Returns chunk POSITION and the LIST of possible
-- chunks that could be spawned here.
local function next_potential(random, potential)
	-- No potentials available? Return nil.
	if not next(potential) then return nil end

	-- Build array listing all potential location hashes and chunk sets.
	-- An ordered array is necessary to sort them and chose highest priority.
	local array = {}
	for positionhash, chunks in pairs(potential) do
		local chunkcount = 0
		for chunkname, _ in pairs(chunks) do
			chunkcount = chunkcount + 1
		end
		array[#array + 1] = {
			chunkpos = positionhash,
			chunkcount = chunkcount,
		}
	end

	-- Now sort the array so that lowest-entropy potentials are at the front.
	table.sort(array, function(a, b) return a.chunkcount < b.chunkcount end)

	-- Now build an array of all potentials at front with the same chunk count.
	-- These are considered "ties" which must be broken RANDOMLY.
	local firstcount = array[1].chunkcount
	local ties = {}
	for k, v in ipairs(array) do
		if v.chunkcount == firstcount then
			ties[#ties + 1] = v
		else
			break
		end
	end

	-- Now choose random from the list of tied potentials.
	-- This is what we'll return to the caller, as position-hash + chunk names.
	local choice = ties[random(1, #ties)]
	return choice.chunkpos, potential[choice.chunkpos]
end



-- Select a random chunk; must return the chosen chunk's name.
-- We take into account the chunk's probability, but this only matters if
-- there are multiple possible chunk names to choose from.
local function choose_chunk(random, all, available, ignore)
	local allchoices = {}
	local choices = {}

	-- First build array from dictionary set.
	for name, _ in pairs(available) do
		local prob = (all[name].probability or 100)
		if prob > 0 then  -- Skip zero-prob choices to optimize
			if not ignore[name] then -- Skip chunks being ignored.
				choices[#choices + 1] = {name=name, prob=prob}
			end
		end

		-- This will be used as fallback incase zero-prob elements result in there
		-- being no elements in the 'choices' array.
		allchoices[#allchoices + 1] = {name=name, prob=prob}
	end

	-- Now, add up all the probabilities to find a max value.
	-- Max prob should never be zero. But it might be (e.g., testing), so handle
	-- it.
	local max_prob = 0
	for k, v in ipairs(choices) do max_prob = max_prob + v.prob end

	-- Fallback to uniform selection if necessary.
	if max_prob == 0 or #choices == 0 then
		if #allchoices > 0 then
			return allchoices[random(1, #allchoices)].name
		end
		-- Function precondition broken (there never was anything to select).
		return nil
	end

	-- Now get a random int from 1 to max prob.
	local number = random(1, max_prob)

	-- Now find out which name our number matches, and return that.
	-- Cumulative selection.
	local cumulative = 0
	for _, v in ipairs(choices) do
		cumulative = cumulative + v.prob
		if number <= cumulative then
			return v.name
		end
	end

	-- Fallback, if for some reason we get here (shouldn't happen).
	return choices[random(1, #choices)].name
end



-- Query whether a chunk position is within max extents.
-- This prevents the fortress generator from generating infinitely.
local function within_extents(pos, extent)
	local minp = {
		x = -extent.x,
		y = -extent.y,
		z = -extent.z,
	}
	local maxp = {
		x = extent.x,
		y = extent.y,
		z = extent.z,
	}

	if pos.x >= minp.x and pos.x <= maxp.x
			and pos.y >= minp.y and pos.y <= maxp.y
			and pos.z >= minp.z and pos.z <= maxp.z then
		return true
	end
end



-- Query whether a chunk position is NEAR maximum fortress boundaries.
-- This lets us smoothly end the fortress by culling non-fallback chunks from
-- the available chunks we can spawn, so we don't generate sudden cutoffs.
local function near_extents(pos, extent)
	local minp = {
		x = -extent.x,
		y = -extent.y,
		z = -extent.z,
	}
	local maxp = {
		x = extent.x,
		y = extent.y,
		z = extent.z,
	}
	minp = vector.offset(minp, 2, 2, 2)
	maxp = vector.offset(maxp, -2, -2, -2)

	if pos.x <= minp.x or pos.x >= maxp.x
			or pos.y <= minp.y or pos.y >= maxp.y
			or pos.z <= minp.z or pos.z >= maxp.z then
		return true
	end
end



-- Filter chunk names by their global usage limits.
local function get_limited_chunks(all_chunks, chunk_limits)
	local filtered = {}
	for chunkname, thischunk in pairs(all_chunks) do
		if thischunk.limit then
			if (chunk_limits[chunkname] or 0) < thischunk.limit then
				filtered[chunkname] = true
			end
		else
			-- No limit applied to this chunk name.
			filtered[chunkname] = true
		end
	end
	return filtered
end



-- Filter chunk names by their fallback flag.
-- These are the only chunks allowed to be placed at the fortress extent
-- limits.
local function get_fallback_chunks(all_chunks, chunk_limits)
	local filtered = {}
	for chunkname, thischunk in pairs(all_chunks) do
		if thischunk.fallback then
			filtered[chunkname] = true
		end
	end
	return filtered
end



-- Given a max bounding box size (from origin), make a list of all the negative
-- offsets that could be added to shift the box around the origin.
local function calculate_negative_offsets(size)
	local v = size
	local a = {}
	for x = 0, v.x - 1 do
		for y = 0, v.y - 1 do
			for z = 0, v.z - 1 do
				a[#a + 1] = {x=-x, y=-y, z=-z}
			end
		end
	end
	return a
end



-- Write a chunk's footprint (if it has one) into the list of determined chunks.
local function write_footprint(params, chunkpos, chunkdata)
	local override = params.override_chunk_schems
	local determined = params.traversal.determined
	local potential = params.traversal.potential
	local footprint = chunkdata.footprint
	local poshash = HASH_POSITION(chunkpos)

	-- Most chunks don't define this.
	-- We don't need to do anything for them.
	if not footprint then return end

	for hashpos, name in pairs(footprint) do
		local neighborpos = vector.add(chunkpos, UNHASH_POSITION(hashpos))
		local neighborhash = HASH_POSITION(neighborpos)

		-- Note that a chunk's footprint is allowed to specify the names of other,
		-- unrelated chunks, in case you want the algorithm to treat those locations
		-- as if they were actually occupied by those other chunks. For example,
		-- a combined bridge/hallway chunk (taking up 2 tiles of space) could have a
		-- footprint that defines its "bridge part" as an ordinary bridge, and the
		-- "hallway part" could simply be named as another existing hallway piece.
		determined[neighborhash] = name

		-- Make sure all potentials within this footprint are empty.
		-- We should already have assured that this is the case by reading from
		-- 'require_empty_neighbors' defined in the chunk data, but if that data is
		-- bad, this WILL create a bug. The fix is to fix your data.
		potential[neighborhash] = nil

		-- Notify the schematic placer: fill entire footprint with IGNORE.
		-- This tells the schem placer that this location needs special handling,
		-- because what is in 'determined' isn't the actual schematic we place.
		override[neighborhash] = "IGNORE" -- Special value.
	end

	-- Notify the schematic placer.
	override[poshash] = chunkname
end



-- This is the core of the Wave Function Collapse (TM) algorithm.
-- It's just marketing lingo. This is actually just a rules-constraint system.
-- Function must be called in a loop until it says 'enough!'
function fortress.v2.process_chunk(params)
	-- Core queues/lists used by the algorithm.
	local all_chunks = params.chunks
	local chunk_names = params.chunk_names
	local determined = params.traversal.determined
	local potential = params.traversal.potential
	local chunk_limits = params.chunk_limits
	local override_chunk_schems = params.override_chunk_schems
	local random = params.yeskings

	-- Helper function to shorten long lines in conditionals.
	-- Return true if a hash-location is already occupied by part of another
	-- fortress.
	local function IS_CLAIMED(hash)
		local spawn_pos = params.spawn_pos
		local chunk_step = params.step
		local occupied = fortress.v2.OCCUPIED_LOCATIONS
		return already_claimed(spawn_pos, chunk_step, hash, occupied)
	end

	-- Chose next potential to expand/compute, with lowest-entropy chunks having
	-- highest priority, and ties broken randomly.
	local originalposhash, selectable_chunks = next_potential(random, potential)
	local all_limited_chunks = get_limited_chunks(all_chunks, chunk_limits)
	local all_fallback_chunks = get_fallback_chunks(all_chunks, chunk_limits)

	-- List of chunks that fail the neighbor test,
	-- so we ignore them when trying again.
	local ignore_chunks = {}

	-- No new possibilities? We're done.
	if not originalposhash then return end

	-- We will jump here if neighbor checks failed.
	-- Abort entirely if we do this too many times (prevent infinite loop).
	local try_again_count = 0
	local try_again_limit = 100
	::try_again::
	try_again_count = try_again_count + 1

	-- Step 0: select a random chunk from the list of possibilities.
	-- This takes into account competing chunk probabilities.
	-- BUG: sometimes chunkname is nil? But this should not happen unless somehow
	-- there are NO 'selectable_chunks' to choose from, but how could that happen?
	local chunkname = choose_chunk(
		random, all_chunks, selectable_chunks, ignore_chunks)

	local chunkpos = UNHASH_POSITION(originalposhash)
	local original_chunkpos = vector.copy(chunkpos)
	local chunkdata = all_chunks[chunkname]
	local neighbors_to_update -- Placeholder in scope.

	-- Handle this hopefully very rare error.
	if not chunkname or not chunkdata then
		params.algorithm_fail = true
		params.log("error", "Fail: chunkname or chunkdata is nil! Giving up.")
		return
	end

	if try_again_count > try_again_limit then
		local array_possibilities = {}
		for name, _ in pairs(potential[originalposhash]) do
			array_possibilities[#array_possibilities + 1] = name
		end

		params.log("warning", "Iteration canceled!")
		params.log("warning", "Chunk: " .. chunkname)
		params.log("warning", "Pos: " .. POS_TO_STR(chunkpos))
		params.log("warning", "After " .. try_again_limit .. " iterations.")
		params.log("warning", "Remaining available choices were: {" ..
			table.concat(array_possibilities, ", ") .. "}")

		-- Don't allow an incomplete fortress to be spawned for players!
		-- It looks stupid and unprofessional.
		params.bad_chunkpos = chunkpos
		params.algorithm_fail = true
		return
	end

	-- Support for large chunks (greater than 1x1x1 units).
	--
	-- Calculate all the possible offsets we could give this chunk to satisfy its
	-- neighbor conditions. We will try to fit the chunk with each offset in turn,
	-- until we find a suitable offset or we run out of offsets (in which case we
	-- will know there is no possible room for this chunk).
	local offsets = calculate_negative_offsets(chunkdata.size or {x=1, y=1, z=1})
	local current_offset = 0

	-- We will jump here if the chunk failed the neighbor checks, but there are
	-- still more offsets to try. If we run out of offsets then we error.
	::try_next_offset::
	current_offset = current_offset + 1

	if current_offset > #offsets then
		ignore_chunks[chunkname] = true
		goto try_again
	end

	-- Calculate chunk position adjusted by currently chosen offset.
	-- Don't bork the original chunk pos.
	chunkpos = vector.add(original_chunkpos, offsets[current_offset])

	--[[
	params.log("action",
		"Processing chunk: " .. chunkname .. " at " .. POS_TO_STR(chunkpos) ..
		", try count: " .. try_count .. ", offset: " .. current_offset)
	--]]

	-- If any of the chunk's required empty neighbors aren't empty, we cannot
	-- place this chunk here.
	if chunkdata.require_empty_neighbors then
		local function in_list(list)
			for k, v in pairs(list) do
				if k == chunkname then
					return true
				end
			end
		end

		for hashpos, _ in pairs(chunkdata.require_empty_neighbors) do
			local neighborpos = vector.add(chunkpos, UNHASH_POSITION(hashpos))
			local neighborhash = HASH_POSITION(neighborpos)

			-- The "potential" location is considered to be occupied if that location
			-- exists AND our current chunk name is NOT in the list of potentials.
			---[[
			if (determined[neighborhash] or IS_CLAIMED(neighborhash)) or
					(potential[neighborhash] and not in_list(potential[neighborhash]))
						then
			--]]
			--[[
			if determined[neighborhash] or potential[neighborhash] then
			--]]
				-- If we still have more possible offsets to try for this chunk,
				-- then don't skip this chunk just yet. Try next offset.
				if current_offset < #offsets then goto try_next_offset end

				ignore_chunks[chunkname] = true

				--[[
				params.log("action",
					"Can't place " .. chunkname .. " at " .. POS_TO_STR(chunkpos) ..
						", adding to ignore list.")
				--]]

				goto try_again
			end
		end
	end

	-- Step 1: collect neighbors. We only do this if the selected chunk defines
	-- neighbors. If it does, those neighbors must be matched against any existing
	-- neighbors already contained in the 'potential' list (indexed by hash).
	if chunkdata.valid_neighbors then
		-- The chunk defines which neighbors it cares about. If any possible
		-- direction defines NO NEIGHBORS for this direction, we interpret that ALL
		-- neighbors are permitted without restriction.
		local all_neighbors = chunkdata.valid_neighbors
		neighbors_to_update = {}

		-- This will contain the dir hashes of neighbors we determine we must
		-- ignore even though the chunk defines them (e.g., we're at extent
		-- boundaries).
		local dirs_to_ignore = {}

		-- Compute additional intersections to narrow down the lists.
		for dir, dir_neighbors in pairs(all_neighbors) do
			-- Since 'chunk_names' contains ALL chunk names, this should result in a
			-- list containing just the valid chunk neighbors for current chunk. Leave
			-- this as a sanity check (in case a chunk defines neighbors in its data
			-- that don't actually exist).
			local filt = intersect(chunk_names, dir_neighbors)

			local neighborpos = vector.add(chunkpos, UNHASH_POSITION(dir))
			local neighborhash = HASH_POSITION(neighborpos)

			-- If defined neighbors exist in the 'potential' list, the result must be
			-- the INTERSECTION of both lists. This might result in the list being
			-- EMPTY, which indicates we need to backtrack/try again.
			if potential[neighborhash] then
				filt = intersect(filt, potential[neighborhash])
			end

			-- This also might result in the list becoming empty, if the already-
			-- determined neighbor isn't a valid neighbor of the selected chunk.
			if determined[neighborhash] then
				local detchunk = determined[neighborhash]
				filt = intersect(filt, {[detchunk]=true})
			elseif IS_CLAIMED(neighborhash) then
				local detchunk = IS_CLAIMED(neighborhash)
				filt = intersect(filt, {[detchunk]=true})
			else
				-- Filter chunks by limits. This has to be done EXCLUSIVE of checking
				-- allowed neighbors against already-determined neighbors (see above)
				-- because that neighbor may have been the last allowed per limits.
				filt = intersect(all_limited_chunks, filt)
			end

			-- Add neighbors for this direction only if in bounds (prevents infinite
			-- neighbor expansion).
			if within_extents(neighborpos, params.max_extent) then
				-- If near extent boundaries, additionally filter chunks, allowing only
				-- fallback chunks to be used here.
				if near_extents(neighborpos, params.max_extent) then
					neighbors_to_update[dir] = intersect(all_fallback_chunks, filt)
				else
					neighbors_to_update[dir] = filt
				end
			else
				-- Otherwise add this direction to the set of dirs to REMOVE entirely.
				-- This neighbor position is outside extent bounds!
				dirs_to_ignore[dir] = true
			end
		end

		-- Delete directions that exceed fort bounds.
		-- Do not simply leave their lists empty, because that would confuse things.
		for dir, _ in pairs(dirs_to_ignore) do
			neighbors_to_update[dir] = nil
		end

		-- Now (and this is very important) if any of the neighbor lists are EMPTY,
		-- we have made a mistake and we must cancel this iteration, so we can
		-- hopefully chose a different path the next time we enter this function.
		-- This obviously skips directions that we explicitly ignored earlier.
		for _, neighbors in pairs(neighbors_to_update) do
			if not next(neighbors) then
				-- If we still have more possible offsets to try for this chunk,
				-- then don't skip this chunk just yet. Try next offset.
				if current_offset < #offsets then goto try_next_offset end

				ignore_chunks[chunkname] = true

				--[[
				params.log("action",
					"Can't place " .. chunkname .. " at " .. POS_TO_STR(chunkpos) ..
						", adding to ignore list.")
				--]]

				goto try_again
			end
		end
	end

	-- Step 2: add current chunk to list of fully-determined chunks.
	-- Remove this entry from the list of indeterminate (possible) chunks.
	local finalposhash = HASH_POSITION(chunkpos)
	determined[finalposhash] = chunkname
	potential[originalposhash] = nil

	-- Also list all chunks placed in an array of {name, hash} pairs.
	params.chunk_usage[#params.chunk_usage + 1] =
		{name=chunkname, hash=finalposhash}

	-- Apply the chunk's footprint, which can be larger than a single chunk.
	-- This is required for chunks larger than 1x1x1 chunk/tile units.
	write_footprint(params, chunkpos, chunkdata)

	-- Step 3: update the limits count.
	chunk_limits[chunkname] = (chunk_limits[chunkname] or 0) + 1

	-- Step 4: update neighbor lists.
	-- We skip this if the current chunk (we just added to 'determined') has no
	-- defined neighbors.
	if neighbors_to_update then
		for dir, chunks in pairs(neighbors_to_update) do
			if next(chunks) then -- Keep data structure clean; skip empties.
				-- Calculate the index hash of the neighboring position.
				local neighborpos = vector.add(chunkpos, UNHASH_POSITION(dir))
				local neighborhash = HASH_POSITION(neighborpos)

				-- Also, do not add to 'potential' if already defined in 'determined.'
				-- This prevents trying to overwrite parts already generated.
				if not determined[neighborhash] and not IS_CLAIMED(neighborhash) then
					local finalchunks = chunks

					-- Finally, if the chunkdata defines enabled neighbors, we should
					-- additionally filter the neighbor chunk list by that.
					--
					-- Note that if 'enabled_neighbors' is not present then only data from
					-- 'valid_neighbors' is used (filtered as above in this function).
					if chunkdata.enabled_neighbors then
						local enabled_dir = chunkdata.enabled_neighbors[dir]
						if enabled_dir then
							finalchunks = intersect(chunks, enabled_dir)
						end
					end

					potential[neighborhash] = finalchunks
				end
			end
		end
	end

	-- Finished one iteration successfully.
	return true
end
